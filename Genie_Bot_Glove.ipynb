{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vD7wcI8W9uAk",
        "outputId": "f00c6b68-2f2b-4816-8456-e0f1a5a2c17d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-56cfa0c3-8be5-4f0a-8733-8a70ef4ed897\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-56cfa0c3-8be5-4f0a-8733-8a70ef4ed897\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving intents.json to intents (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents.json': b'{\\n  \"intents\": [\\n    {\\n      \"tag\": \"greeting\",\\n      \"patterns\": [\\n        \"Hi\",\\n\\t  \"Hi Bot\",\\n\\t  \"Hola\",\\n\\t  \"Hi, how are you\",\\n        \"How are you\",\\n        \"Is anyone there?\",\\n        \"Hello\",\\n        \"Hey\",\\n        \"What\\'s up\",\\n        \"Hi there\",\\n        \"Hey there\",\\n        \"Good morning\",\\n        \"Good afternoon\",\\n        \"Good evening\",\\n        \"Howdy\",\\n        \"Hello there\"\\n      ],\\n      \"responses\": [\\n        \"What can i help you with today?\",\\n        \"How can I help you today?\"\\n      ],\\n      \"context_set\": \"\"\\n    },\\n    {\\n      \"tag\": \"goodbye\",\\n      \"patterns\": [\\n        \"Bye\",\\n        \"See you later\",\\n        \"Goodbye\",\\n        \"Farewell\",\\n        \"Take care\",\\n        \"Catch you later\",\\n        \"Goodbye for now\",\\n        \"Bye for now\",\\n        \"Talk to you later\",\\n        \"See you soon\",\\n        \"Take it easy\",\\n        \"So long\",\\n        \"Adios\",\\n        \"Good night\",\\n        \"Later\",\\n        \"Have a good one\",\\n        \"Cheers\",\\n        \"Good luck\",\\n        \"Safe travels\",\\n        \"Until next time\"\\n      ],\\n      \"responses\": [\\n        \"See you later, thanks for visiting\",\\n        \"Have a nice day\",\\n        \"Bye! Come back again soon.\"\\n      ],\\n      \"context_set\": \"\"\\n    },\\n    {\\n      \"tag\": \"thanks\",\\n      \"patterns\": [\\n        \"Thanks\",\\n        \"Thank you\",\\n        \"That\\'s helpful\",\\n        \"Much appreciated\",\\n        \"Thanks a lot\",\\n        \"Thanks so much\",\\n        \"Thank you very much\",\\n        \"I appreciate it\",\\n        \"You\\'re a lifesaver\",\\n        \"I owe you one\",\\n        \"You\\'re the best\",\\n        \"Thanks for the help\",\\n        \"You\\'re awesome\",\\n        \"I appreciate your help\",\\n        \"You\\'re amazing\",\\n        \"Grateful for your help\",\\n        \"Thanks for your assistance\",\\n        \"You\\'re a big help\",\\n        \"That\\'s so kind of you\",\\n        \"I can\\'t thank you enough\"\\n      ],\\n      \"responses\": [\\n        \"Happy to help!\",\\n        \"Any time!\",\\n        \"My pleasure\"\\n      ],\\n      \"context_set\": \"\"\\n    },\\n {\\n     \"tag\": \"catering\",\\n\"patterns\": [\\n\"Do you offer catering services?\",\\n\"Can you cater for events?\",\\n\"Are you available for catering?\",\\n\"Can I hire you for catering?\",\\n\"What types of events do you cater for?\",\\n\"What is your catering menu?\",\\n\"Can you create a custom catering menu?\",\\n\"What is your capacity for catering events?\",\\n\"Do you have experience catering for large events?\",\\n\"What is the cost of your catering services?\",\\n\"Do you offer on-site catering?\",\\n\"Can you accommodate dietary restrictions or special requests?\",\\n\"How far in advance should I book your catering services?\",\\n\"What is included in your catering services?\",\\n\"Do you provide serving staff for catering events?\",\\n\"Can you handle last-minute catering requests?\",\\n\"Do you provide all necessary equipment for catering events?\",\\n\"Can you assist with event planning and coordination?\",\\n\"Do you offer delivery for catering orders?\"\\n],\\n      \"responses\": [\\n        \"We will be more than happy to serve fresh food to make your event more memorable. Feel free to call us at (669)-224-0833\",\\n        \"At Suggi OOta, we offer top-notch catering services to help make your event a success. Give us a call at (669)-224-0833 to learn more and to place your order.\",\\n        \"We\\'d love to help make your event unforgettable with our fresh and delicious food. Feel free to give us a call at (669)-224-0833 to discuss your catering needs.\"\\n      ],\\n      \"context_set\": \"\"\\n    },\\n    {\\n      \"tag\": \"hours\",\\n      \"patterns\": [\\n        \"What hours are you open?\",\\n        \"What are your hours?\",\\n        \"When are you open?\",\\n        \"Tell me your hours\",\\n        \"What time do you open?\",\\n        \"What time do you close?\",\\n        \"When do you close?\",\\n        \"What\\'s your schedule?\",\\n\\t  \"what are today\\'s timings?\",\\n        \"Are you open now?\",\\n        \"What are your business hours?\",\\n        \"What are your working hours?\",\\n        \"When can I visit?\",\\n        \"What are your opening hours?\",\\n        \"What are your closing hours?\",\\n        \"What days are you open?\",\\n        \"When do you open?\",\\n        \"When do you close?\",\\n        \"Are you open on weekends?\",\\n        \"Are you open on holidays?\",\\n        \"What time are you open?\"\\n      ],\\n      \"responses\": [\\n        \"We\\'re open every day from 11am-9pm, except on Mondays when we\\'re closed. On Fridays, we\\'re open from 4pm-9pm.\",\\n        \"Our hours are 11am-9pm every day, except for Mondays when we\\'re closed. Fridays, we\\'re open from 4pm-9pm.\"\\n      ],\\n      \"context_set\": \"\"\\n},\\n{\\n\"tag\": \"location\",\\n\"patterns\": [\\n\"What is your location?\",\\n\"Where are you located?\",\\n\"What is your address?\",\\n\"Where is your restaurant situated?\",\\n\"How can I find you?\",\\n\"What\\'s your location?\",\\n\"Where can I find you?\",\\n\"Where are you?\",\\n\"What\\'s the address?\",\\n\"Where is your place?\",\\n\"Where is your business located?\",\\n\"What street are you on?\",\\n\"Which area is your restaurant in?\",\\n\"What\\'s your physical location?\",\\n\"Where should I go?\",\\n\"Where is your store?\",\\n\"Where is your shop?\",\\n\"What\\'s the location\",\\n\"Can you provide the address\",\\n\"Where do I find you\",\\n\"What is your location\",\\n\"Where are you located\",\\n\"What is your address\",\\n\"Where is your restaurant situated\",\\n\"How can I find you\",\\n\"What\\'s your location\",\\n\"Where can I find you\",\\n\"Where are you\",\\n\"What\\'s the address\",\\n\"Where is your place\",\\n\"Where is your business located\",\\n\"What street are you on\",\\n\"Which area is your restaurant in\",\\n\"What\\'s your physical location\",\\n\"Where should I go\",\\n\"Where is your store\",\\n\"Where is your shop\",\\n\"What\\'s the location\",\\n\"Can you provide the address\",\\n\"Where do I find you\"\\n],\\n\"responses\": [\\n\"We are one of the Cloud Kitchens (K-31) located at 949 Ruff Dr, San Jose, CA 95110. Please follow the link to visit us: https://www.google.com/maps?q=949+Ruff+Dr,+San+Jose,+CA+95110\"],\\n\"context_set\": \"\"\\n},\\n{\\n\"tag\": \"contact\",\\n\"patterns\": [\\n\"How can I contact you?\",\\n\"What\\'s your phone number?\",\\n\"Can I call you?\",\\n\"May I have your contact information?\",\\n\"What are your contact details?\",\\n\"Can you provide your phone number?\",\\n\"How do I reach you?\",\\n\"How do I get in touch with you?\",\\n\"What\\'s the best way to contact you?\",\\n\"Do you have an email address?\",\\n\"Is there a way to email you?\",\\n\"Can I reach out to you via email?\",\\n\"Can you give me your contact number?\",\\n\"What is the best way to get in touch with your restaurant?\",\\n\"What is your phone number?\",\\n\"What are your phone lines?\",\\n\"Can I have your email address?\",\\n\"Can you provide your contact details?\",\\n\"How can I get in touch with your business?\",\\n\"What\\'s your email address?\",\\n\"How do I contact your restaurant?\",\\n\"How can I reach your restaurant?\",\\n\"How do I make a reservation?\",\\n\"How do I book a table?\",\\n\"What is the best way to make a reservation?\",\\n\"How can I contact you\",\\n\"What\\'s your phone number\",\\n\"Can I call you\",\\n\"May I have your contact information\",\\n\"What are your contact details\",\\n\"Can you provide your phone number\",\\n\"How do I reach you\",\\n\"How do I get in touch with you\",\\n\"What\\'s the best way to contact you\",\\n\"Do you have an email address\",\\n\"Is there a way to email you\",\\n\"Can I reach out to you via email\",\\n\"Can you give me your contact number\",\\n\"What is the best way to get in touch with your restaurant\",\\n\"What is your phone number\",\\n\"What are your phone lines\",\\n\"Can I have your email address\",\\n\"Can you provide your contact details\",\\n\"How can I get in touch with your business\",\\n\"What\\'s your email address\",\\n\"How do I contact your restaurant\",\\n\"How can I reach your restaurant\",\\n\"How do I make a reservation\",\\n\"How do I book a table\",\\n\"What is the best way to make a reservation\"\\n],\\n\"responses\": [\\n\"Feel free to call us at (669)-224-0833 from 11 am-9pm on everyday except Mondays\",\\n\"Please give us a call at (669)-224-0833 from 11 am-9pm on everyday except Mondays\",\\n\"We would love to hear from you! You can contact us at (669)-224-0833 from 11 am-9pm on everyday except Mondays\"\\n],\\n\"context_set\": \"\"\\n},\\n\\n{\\n\"tag\": \"payments\",\\n\"patterns\": [\\n\"Do you take credit cards?\",\\n\"Do you accept Mastercard?\",\\n\"Are you cash only?\",\\n\"What payment methods do you accept?\",\\n\"Can I pay with a credit card?\",\\n\"Do you accept debit cards?\",\\n\"Do you take Visa?\",\\n\"Can I pay with cash?\",\\n\"Do you accept American Express?\",\\n\"What cards do you accept?\",\\n\"Do you take checks?\",\\n\"Do you accept Apple Pay?\",\\n\"Can I use Google Pay?\",\\n\"Do you accept PayPal?\",\\n\"What are the payment options?\",\\n\"How can I pay?\",\\n\"Is it card only?\",\\n\"Do you have a cashless policy?\",\\n\"Do you accept contactless payments?\",\\n\"Can I use my credit card?\"\\n],\\n\"responses\": [\\n\"We accept VISA, Mastercard and AMEX\",\\n\"We accept most major credit cards\"\\n],\\n\"context_set\": \"\"\\n},\\n{\\n\"tag\": \"todaysmenu\",\\n\"patterns\": [\\n\"What is your menu for today?\",\\n\"What are you serving today?\",\\n\"What is today\\'s special?\",\\n\"What\\'s on the menu?\",\\n\"What are today\\'s specials?\",\\n\"Any new dishes today?\",\\n\"What should I try today?\",\\n\"What\\'s the special?\",\\n\"What do you recommend today?\",\\n\"What are the daily specials?\",\\n\"What\\'s good today?\",\\n\"What\\'s the best thing on the menu today?\",\\n\"What\\'s new on the menu?\",\\n\"What\\'s your chef\\'s recommendation?\",\\n\"What\\'s the most popular dish today?\",\\n\"What\\'s your top dish for today?\",\\n\"What are the chef\\'s specials?\",\\n\"What\\'s the dish of the day?\",\\n\"Any special offers today?\",\\n\"What are the featured items?\"\\n],\\n\"responses\": [\\n\"Our menu is a daily changing menu as we prepare everything from scratch on the same day, Please visit https://www.suggioota.com/order-online for more information.\",\\n\"Our daily changing menu features only fresh, made-from-scratch meals, using the best seasonal ingredients. Please visit https://www.suggioota.com/order-online to explore our menu.\"\\n],\\n\"context_set\": \"\"\\n},\\n{\\n\"tag\": \"deliveryoption\",\\n\"patterns\": [\\n\"Do you provide home delivery?\",\\n\"Do you deliver the food?\",\\n\"What are the home delivery options?\",\\n\"Do you offer delivery?\",\\n\"Is there a delivery option?\",\\n\"Can I get my food delivered?\",\\n\"What delivery services do you use?\",\\n\"How does delivery work?\",\\n\"Do you have a delivery service?\",\\n\"Can you deliver to my house?\",\\n\"Do you partner with any delivery apps?\",\\n\"Which delivery apps do you work with?\",\\n\"Can I order delivery?\",\\n\"What\\'s your delivery range?\",\\n\"How much is delivery?\",\\n\"Is there a delivery fee?\",\\n\"How long does delivery take?\",\\n\"Do you do contactless delivery?\",\\n\"Can I track my delivery?\"\\n],\\n\"responses\": [\\n\"Yes, we provide home delivery through Doordash, Uber Eats, Grubhub, and LemonHat\",\\n\"We have home delivery options through Doordash, Uber Eats, Grubhub, and LemonHat\"\\n],\\n\"context_set\": \"food\"\\n},\\n{\\n\"tag\": \"menu\",\\n\"patterns\": [\\n\"What is your Menu?\",\\n\"What are the main course options?\",\\n\"Can you tell me the most delicious dish from the menu?\",\\n\"What is the today\\'s special?\",\\n\"What do you serve?\",\\n\"Can I see the menu?\",\\n\"What\\'s on the menu?\",\\n\"What are your best dishes?\",\\n\"What do you recommend?\",\\n\"Tell me about your menu\",\\n\"What kind of food do you have?\",\\n\"What\\'s your most popular dish?\",\\n\"Do you have any signature dishes?\",\\n\"What are your top menu items?\",\\n\"What kind of cuisine do you serve?\",\\n\"What are your appetizers?\",\\n\"What are your desserts?\",\\n\"What are your specials?\",\\n\"What are your vegan options?\",\\n\"Do you have gluten-free options?\"\\n],\\n\"responses\": [\\n\"You can visit https://www.suggioota.com/order-online for menu options\",\\n\"You can check out the food menu at https://www.suggioota.com/order-online\"\\n],\\n\"context_filter\": \"food\"\\n},\\n{\\n\"tag\": \"order\",\\n\"patterns\": [\\n\"I\\'d like to order\",\\n\"Can you take my order?\",\\n\"What do you have on the menu?\",\\n\"What\\'s good to eat?\",\\n\"What\\'s your recommendation?\",\\n\"Can you suggest something?\",\\n\"What do you suggest?\",\\n\"I want to place an order\",\\n\"Can I order some food?\",\\n\"How can I order?\",\\n\"order food\",\\n\"i want to order\",\\n\"What\\'s the best thing to order?\",\\n\"What should I get?\",\\n\"What do you think I should try?\",\\n\"I need help deciding what to order\",\\n\"I\\'m not sure what to get\",\\n\"I can\\'t decide what to order\",\\n\"What are your customer favorites?\",\\n\"What would you recommend for a first-timer?\",\\n\"What\\'s a must-try dish?\",\\n\"What\\'s a good option for lunch?\"\\n],\\n\"responses\": [\\n\"Sure, You can place your order online at https://www.suggioota.com/order-online\",\\n\"Of course, You can place your order online at https://www.suggioota.com/order-online\",\\n\"We have many great options to choose from, You can place your order online at https://www.suggioota.com/order-online\"\\n],\\n\"context_set\": \"\"\\n}\\n]\\n}\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "# Load pre-trained GloVe model\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n"
      ],
      "metadata": {
        "id": "e0PV8qN2C3iJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec74976-578c-4d78-f6aa-9fec0876e184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYPRjvkx805q",
        "outputId": "3cdb835b-b4df-4f2f-ef26-f2d2783f80d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from tensorflow import keras\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the GloVe word vectors\n",
        "glove_model = KeyedVectors.load_word2vec_format('path_to_glove_file', binary=False)\n",
        "\n",
        "# Load the intents data\n",
        "with open(\"intents.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Preprocessing\n",
        "vocab = set()\n",
        "classes = []\n",
        "documents = []\n",
        "\n",
        "for intent in data[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        pattern = pattern.rstrip(\"?\")\n",
        "        tokens = word_tokenize(pattern)\n",
        "        tokens = [token.lower() for token in tokens if token not in set(stopwords.words(\"english\"))]\n",
        "        vocab.update(tokens)\n",
        "        documents.append((tokens, intent[\"tag\"]))\n",
        "    if intent[\"tag\"] not in classes:\n",
        "        classes.append(intent[\"tag\"])\n",
        "\n",
        "# Generate word embeddings for each token using GloVe\n",
        "X = []\n",
        "y = []\n",
        "for doc in documents:\n",
        "    vecs = []\n",
        "    for token in doc[0]:\n",
        "        if token in glove_model.vocab:\n",
        "            vecs.append(glove_model[token])  # Get the GloVe word embedding for the token\n",
        "    if vecs:\n",
        "        vecs = np.mean(vecs, axis=0)  # Calculate the mean word embedding for the document\n",
        "        X.append(vecs)\n",
        "        y.append(classes.index(doc[1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Build the model\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(128, input_dim=len(X_train[0]), activation=\"relu\"))  # Input layer with ReLU activation\n",
        "model1.add(Dropout(0.5))  # Dropout layer to prevent overfitting\n",
        "model1.add(Dense(64, activation=\"relu\"))  # Hidden layer with ReLU activation\n",
        "model1.add(Dense(len(classes), activation=\"softmax\"))  # Output layer with softmax activation for multi-class classification\n",
        "\n",
        "model1.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])  # Compile the model\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto', restore_best_weights=True)\n",
        "# Define an early stopping callback to monitor the validation loss during training\n",
        "# It will stop training if the validation loss doesn't improve for 20 epochs\n",
        "# verbose=1 prints messages about the early stopping process\n",
        "# mode='auto' determines the direction of improvement (minimizing loss)\n",
        "# restore_best_weights=True restores the weights of the model to the ones with the best performance on the validation set\n",
        "\n",
        "# Train the model\n",
        "model1.fit(X_train, y_train, epochs=200, validation_split=0.2, batch_size=5, callbacks=early_stop)\n",
        "# Train the model using the training data\n",
        "# Perform 200 epochs, use 20% of the training data as the validation set\n",
        "# Batch size is 5, which means the model will be updated after every 5 samples\n",
        "# The early_stop callback will monitor the validation loss and stop training if it doesn't improve\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model1.evaluate(X_test, y_test)\n",
        "# Evaluate the trained model using the testing data\n",
        "# Calculate the loss and accuracy of the model on the testing data\n",
        "\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
        "# Print the loss and accuracy of the model\n"
      ],
      "metadata": {
        "id": "FcgNGFXz1-K-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4cfe41-8d83-455e-fbac-3cfb34b1379f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "37/37 [==============================] - 6s 9ms/step - loss: 2.4307 - accuracy: 0.1366 - val_loss: 2.1763 - val_accuracy: 0.2826\n",
            "Epoch 2/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 2.1672 - accuracy: 0.2842 - val_loss: 2.0201 - val_accuracy: 0.4130\n",
            "Epoch 3/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.8945 - accuracy: 0.4153 - val_loss: 1.7637 - val_accuracy: 0.5435\n",
            "Epoch 4/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.6371 - accuracy: 0.5246 - val_loss: 1.5147 - val_accuracy: 0.7174\n",
            "Epoch 5/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.4397 - accuracy: 0.5574 - val_loss: 1.2380 - val_accuracy: 0.7174\n",
            "Epoch 6/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.1168 - accuracy: 0.6995 - val_loss: 1.0928 - val_accuracy: 0.7609\n",
            "Epoch 7/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.0883 - accuracy: 0.7541 - val_loss: 0.9878 - val_accuracy: 0.7826\n",
            "Epoch 8/200\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 0.9050 - accuracy: 0.7486 - val_loss: 0.9221 - val_accuracy: 0.7826\n",
            "Epoch 9/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.8032 - accuracy: 0.7814 - val_loss: 0.8702 - val_accuracy: 0.7609\n",
            "Epoch 10/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.7075 - accuracy: 0.7978 - val_loss: 0.8347 - val_accuracy: 0.7609\n",
            "Epoch 11/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.6563 - accuracy: 0.8033 - val_loss: 0.7972 - val_accuracy: 0.7826\n",
            "Epoch 12/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.5909 - accuracy: 0.8306 - val_loss: 0.7551 - val_accuracy: 0.7826\n",
            "Epoch 13/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.8743 - val_loss: 0.7686 - val_accuracy: 0.7826\n",
            "Epoch 14/200\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.8634 - val_loss: 0.6686 - val_accuracy: 0.7826\n",
            "Epoch 15/200\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.8415 - val_loss: 0.7428 - val_accuracy: 0.8043\n",
            "Epoch 16/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.8798 - val_loss: 0.7171 - val_accuracy: 0.8043\n",
            "Epoch 17/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8907 - val_loss: 0.6419 - val_accuracy: 0.8043\n",
            "Epoch 18/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8962 - val_loss: 0.6755 - val_accuracy: 0.8043\n",
            "Epoch 19/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8962 - val_loss: 0.6280 - val_accuracy: 0.8043\n",
            "Epoch 20/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8907 - val_loss: 0.6220 - val_accuracy: 0.8043\n",
            "Epoch 21/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.3058 - accuracy: 0.8962 - val_loss: 0.6381 - val_accuracy: 0.8043\n",
            "Epoch 22/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.9126 - val_loss: 0.6337 - val_accuracy: 0.8043\n",
            "Epoch 23/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.3048 - accuracy: 0.9235 - val_loss: 0.7321 - val_accuracy: 0.8261\n",
            "Epoch 24/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.2848 - accuracy: 0.9235 - val_loss: 0.6292 - val_accuracy: 0.8261\n",
            "Epoch 25/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.2380 - accuracy: 0.9508 - val_loss: 0.6326 - val_accuracy: 0.7826\n",
            "Epoch 26/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.2879 - accuracy: 0.9071 - val_loss: 0.6884 - val_accuracy: 0.8261\n",
            "Epoch 27/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.2367 - accuracy: 0.9344 - val_loss: 0.6029 - val_accuracy: 0.8043\n",
            "Epoch 28/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.2096 - accuracy: 0.9399 - val_loss: 0.6636 - val_accuracy: 0.7826\n",
            "Epoch 29/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.2336 - accuracy: 0.9290 - val_loss: 0.6449 - val_accuracy: 0.8261\n",
            "Epoch 30/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.2433 - accuracy: 0.9344 - val_loss: 0.6268 - val_accuracy: 0.8261\n",
            "Epoch 31/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.2367 - accuracy: 0.9235 - val_loss: 0.6153 - val_accuracy: 0.8043\n",
            "Epoch 32/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.1766 - accuracy: 0.9563 - val_loss: 0.7179 - val_accuracy: 0.8043\n",
            "Epoch 33/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.2120 - accuracy: 0.9290 - val_loss: 0.6109 - val_accuracy: 0.8043\n",
            "Epoch 34/200\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 0.1553 - accuracy: 0.9727 - val_loss: 0.6737 - val_accuracy: 0.8043\n",
            "Epoch 35/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.1538 - accuracy: 0.9563 - val_loss: 0.5809 - val_accuracy: 0.7609\n",
            "Epoch 36/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.1987 - accuracy: 0.9508 - val_loss: 0.6135 - val_accuracy: 0.7826\n",
            "Epoch 37/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.2077 - accuracy: 0.9290 - val_loss: 0.5423 - val_accuracy: 0.8261\n",
            "Epoch 38/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.1830 - accuracy: 0.9617 - val_loss: 0.6950 - val_accuracy: 0.8261\n",
            "Epoch 39/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.9727 - val_loss: 0.7790 - val_accuracy: 0.8261\n",
            "Epoch 40/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.1614 - accuracy: 0.9617 - val_loss: 0.6419 - val_accuracy: 0.8261\n",
            "Epoch 41/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.9672 - val_loss: 0.7074 - val_accuracy: 0.8261\n",
            "Epoch 42/200\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 0.1533 - accuracy: 0.9563 - val_loss: 0.6237 - val_accuracy: 0.8478\n",
            "Epoch 43/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.1712 - accuracy: 0.9508 - val_loss: 0.6219 - val_accuracy: 0.8261\n",
            "Epoch 44/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.1552 - accuracy: 0.9727 - val_loss: 0.7131 - val_accuracy: 0.8043\n",
            "Epoch 45/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.1050 - accuracy: 0.9836 - val_loss: 0.6827 - val_accuracy: 0.8261\n",
            "Epoch 46/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.1263 - accuracy: 0.9672 - val_loss: 0.6956 - val_accuracy: 0.8043\n",
            "Epoch 47/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.1276 - accuracy: 0.9508 - val_loss: 0.5963 - val_accuracy: 0.8478\n",
            "Epoch 48/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.1218 - accuracy: 0.9672 - val_loss: 0.6661 - val_accuracy: 0.8261\n",
            "Epoch 49/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.1378 - accuracy: 0.9672 - val_loss: 0.6980 - val_accuracy: 0.8261\n",
            "Epoch 50/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0943 - accuracy: 0.9672 - val_loss: 0.9185 - val_accuracy: 0.7826\n",
            "Epoch 51/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.9836 - val_loss: 0.7785 - val_accuracy: 0.8261\n",
            "Epoch 52/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 0.1362 - accuracy: 0.9399 - val_loss: 0.7281 - val_accuracy: 0.8043\n",
            "Epoch 53/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 0.1699 - accuracy: 0.9344 - val_loss: 0.6166 - val_accuracy: 0.8478\n",
            "Epoch 54/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.1107 - accuracy: 0.9727 - val_loss: 0.6830 - val_accuracy: 0.8478\n",
            "Epoch 55/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.1180 - accuracy: 0.9617 - val_loss: 0.8709 - val_accuracy: 0.8261\n",
            "Epoch 56/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0905 - accuracy: 0.9781 - val_loss: 0.8650 - val_accuracy: 0.8261\n",
            "Epoch 57/200\n",
            "34/37 [==========================>...] - ETA: 0s - loss: 0.0876 - accuracy: 0.9706Restoring model weights from the end of the best epoch: 37.\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 0.1064 - accuracy: 0.9672 - val_loss: 0.7151 - val_accuracy: 0.8261\n",
            "Epoch 57: early stopping\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5497 - accuracy: 0.8621\n",
            "Loss: 0.5497113466262817, Accuracy: 0.8620689511299133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL2Igk0D9vFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e2e51b3-2206-4edc-e89d-4218349d8762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there, this is Genie. I'm so happy to chat with you today! 😊 \n",
            "Could you please be more specific with your questions.\n",
            "I'm always trying to improve my communication skills and learn from your feedback. (type quit to end the conversation):\n",
            "You: Hi\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "Bot: How can I help you today?\n",
            "You: togo order\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Bot: We have many great options to choose from, You can place your order online at https://www.suggioota.com/order-online\n",
            "You: operational hours\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Bot: Our hours are 11am-9pm every day, except for Mondays when we're closed. Fridays, we're open from 4pm-9pm.\n",
            "You: togo available?\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Bot: I am evolving constantly. I apologize that I could not help you with your query. Please give us a call at  and our team will be happy to assist\n",
            "You: order food\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Bot: We have many great options to choose from, You can place your order online at https://www.suggioota.com/order-online\n",
            "You: ordering services\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Bot: I am evolving constantly. I apologize that I could not help you with your query. Please give us a call at  and our team will be happy to assist\n"
          ]
        }
      ],
      "source": [
        "# Vectorize sentence using GloVe embeddings\n",
        "def vectorize_sentence(sentence, model):\n",
        "    sentence = sentence.rstrip(\"?\")\n",
        "    # tokenize the sentence\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    # lemmatize each word and remove stopwords\n",
        "    sentence_words = [lemmatizer.lemmatize(word.lower(), pos='v') for word in sentence_words if word not in set(stopwords.words(\"english\"))]\n",
        "    # create a vector representation\n",
        "    vecs = []\n",
        "    for word in sentence_words:\n",
        "        if word in model:\n",
        "            vecs.append(model[word])\n",
        "    if vecs:\n",
        "        vecs = np.mean(vecs, axis=0)\n",
        "    else:\n",
        "        vecs = np.zeros(model.vector_size)\n",
        "    return vecs\n",
        "\n",
        "\n",
        "print(\"Hi there, this is Genie. I'm so happy to chat with you today! 😊\")\n",
        "print(\"Could you please be more specific with your questions.\")\n",
        "print(\"I'm always trying to improve my communication skills and learn from your feedback. (type quit to end the conversation):\")\n",
        "\n",
        "while True:\n",
        "    inp = input(\"You: \")  # Get user input\n",
        "    if inp.lower() == \"quit\":\n",
        "        # If the user enters \"quit\", find the \"goodbye\" intent and print a random response\n",
        "        for intent in data[\"intents\"]:\n",
        "            if intent[\"tag\"] == \"goodbye\":\n",
        "                print(\"Bot: \" + random.choice(intent[\"responses\"]))\n",
        "        break  # Exit the loop and end the conversation\n",
        "\n",
        "    vec = vectorize_sentence(inp, model)  # Vectorize the user input using the GloVe embeddings\n",
        "    results = model1.predict(np.array([vec]))  # Make a prediction using the trained model\n",
        "    results_index = np.argmax(results)  # Get the index of the predicted intent\n",
        "    tag = classes[results_index]\n",
        "\n",
        "    if results[0][results_index] > 0.5:\n",
        "        # If the confidence score is above 0.5, find the intent and print a response\n",
        "        for intent in data[\"intents\"]:\n",
        "            if intent[\"tag\"] == tag:\n",
        "                if intent[\"tag\"] == \"goodbye\" and inp == 'quit':\n",
        "                    # If the intent is \"goodbye\" and the user entered \"quit\", print a goodbye message and end the conversation\n",
        "                    print(\"Bot: \" + random.choice(intent[\"responses\"]))\n",
        "                    print(\"Bot: Goodbye!\")\n",
        "                    break\n",
        "                if intent[\"tag\"] == \"goodbye\" and inp != 'quit':\n",
        "                    # If the intent is \"goodbye\" but the user entered something other than \"quit\", print a specific message\n",
        "                    print(\"Bot: I am evolving constantly. I apologize that I could not help you with your query. Please give us a call at  and our team will be happy to assist.\")\n",
        "                else:\n",
        "                    # Print a random response from the intent\n",
        "                    print(\"Bot: \" + random.choice(intent[\"responses\"]))\n",
        "                    break\n",
        "    else:\n",
        "        # If the confidence score is below 0.5, print a generic message\n",
        "        print(\"Bot: I am evolving constantly. I apologize that I could not help you with your query. Please give us a call at  and our team will be happy to assist.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/My Drive/Colab Notebooks' #Declare the path where the code and model file has been placed"
      ],
      "metadata": {
        "id": "p-BlIuhmV1lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save('Genie_word2vec.h5')#save the model"
      ],
      "metadata": {
        "id": "pwcWAsyNcFcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ty3ALqKbJICh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}